# Snakefile for mRNA  in Eukaryotes
import os
from snakemake.utils import R

EXPERIMENT_DIR = "../../"

# species for which pipeline is run
SPECIES = "xxx"

# in an ideal world the database is found by species alone 
GENOME_DB="/xx/xx/xx.dna.genome.fa"
TRANSCRIPTOME_DB="/xx/xx/xx.transcripts.fa"

if not os.path.exists(GENOME_DB):
   sys.exit("Pipeline configuration error: Genome database does not exist.")

if not os.path.exists(TRANSCRIPTOME_DB):
   sys.exit("Pipeline configuration error: Transcriptome database does not exist.")

# reference spikein sequences
SEQDB="/mad/MAD-RBAB/05_Reference-db"
SPIKES_REF = os.path.join(SEQDB,"external/ERCC/ERCC92.fa")

# directory with raw reads in fastq format
FQ_DIR = os.path.join(EXPERIMENT_DIR,"Scratch/raw")
SAMPLES =  [s[:-6] for s in os.listdir(FQ_DIR) if s.endswith(".fastq")]

# spike count table directory
SCRATCH_DIR = os.path.join(EXPERIMENT_DIR,"Scratch/mapped")
RESULT_DIR = os.path.join(EXPERIMENT_DIR,"Results/mapping")
DIR_E = ".dexist"

ASSEMB_DIR = os.path.join(SCRATCH_DIR,"UnmappAssemb21")
ASSEMB_HASH = 21

TMAP_PARAMS = "-M 2 -O 3 -n 16 -g 3 -a 1 -v stage1 map1 map2 map3"

SEQ_COUNT_LOG="seq_count.txt"
READ_TRIM_LEN=50

########################################################################
rule all:
    input: os.path.join(RESULT_DIR,"ReadCounts.txt"),
           os.path.join(RESULT_DIR,"count.png"),
           os.path.join(RESULT_DIR,"CountTable_transc.txt"),
           os.path.join(RESULT_DIR,"CountTable_genome.txt"),
           os.path.join(RESULT_DIR,"CountTable_contigs.txt"),
           os.path.join(RESULT_DIR,"assembly100.fa")
    message: "Done running mRNA pipeline"

########################################################################
rule combine_readcount:
    input:  (SCRATCH_DIR+"/{sample}_readcnt.txt".format(sample=s) for s in SAMPLES)
    output: os.path.join(RESULT_DIR,"ReadCounts.txt")
    message: "Combining counttables into single file"
    shell:
        """
          echo "sample\ttotal\ttrimmed\tspike\ttranscriptome\tgenome\tcontigs\tunmapped" > {output}
          for i in {input} ; do tail -1 ${{i}}  >> {output} ; done
        """

########################################################################
rule combine_mapping_counts:
       input:  (RESULT_DIR+"/{sample}_{mt}_cnt.txt".format(sample=s,mt="{mtype}") for s in SAMPLES)
       output: os.path.join(RESULT_DIR,"CountTable_{mtype}.txt")
       params: samples=("{sample}".format(sample=s) for s in SAMPLES)
       message: "Combining {wildcards.mtype} countables"
       run: R("""
           files=strsplit("{input}"," ")[[1]]
           samples=strsplit("{params.samples}"," ")[[1]]
           transc <- read.table(files[1],stringsAsFactors=F)[,2]
           for (i in files[-1]) transc = unique(c(transc,read.table(i,stringsAsFactors=F)[,2]) )
           transc <- sort(transc);
           res = data.frame(Transcript=transc)
           rownames(res) <- transc
           for (i in 1:length(samples)) {{
                tab = read.table(files[i],stringsAsFactors=F)
                res[,samples[i]] = 0;
                res[tab$V2,samples[i]] = tab$V1
            }}
           write.table(res,"{output}",sep="\\t",quote=F,row.names=F)
           """)

########################################################################
rule contig_count_table:
    input: os.path.join(SCRATCH_DIR,"{sample}_tmap_contigs.sam")
    output: os.path.join(RESULT_DIR,"{sample}_contigs_cnt.txt")
    message: "Create contig count table"
    shell:
         """
             awk '$2 == 0 {{ print $3 }} $2 == 16 {{print $3 "_rc"}}'  {input} | sort | uniq -c > {output}
         """

########################################################################
rule tmap_contigs:
    input: reads=os.path.join(SCRATCH_DIR,"{sample}_tmap_genome_unmapped.fastq"),
           db=SCRATCH_DIR+"/assembly100.fa.tmap.bwt"
    output: os.path.join(SCRATCH_DIR,"{sample}_tmap_contigs.sam")
    message: "tmapping rest to contigs"
    shell:
        """
          tmap mapall -r {input.reads} -f {SCRATCH_DIR}/assembly100.fa {TMAP_PARAMS} > {output}
        """

########################################################################
rule select_unmapped_contigs:
    input: os.path.join(ASSEMB_DIR,"contigs.fa")
    output: os.path.join(SCRATCH_DIR,"assembly100.fa")
    message: "Selecting contigs from assembly"
    shell:
        """
          awk 'BEGIN {{seq=""}} ($1 ~ /^>/) {{ if (seq  && (length(seq) > 99)) {{print name; print seq; }} seq="";   name=$0; next}} {{seq=seq $0}}' {input} > {output}
        """

########################################################################
rule assemble_unmapped:
    input: os.path.join(SCRATCH_DIR,"all_unmapped.fastq")
    output: os.path.join(ASSEMB_DIR,"contigs.fa")
    message: "Assembling ummapped reads"
    shell:
        """
          velveth {ASSEMB_DIR} {ASSEMB_HASH} -fastq {input}
          velvetg {ASSEMB_DIR}
        """

########################################################################
rule combine_unmapped:
    input: (SCRATCH_DIR+"/{sample}_tmap_genome_unmapped.fastq".format(sample=s) for s in SAMPLES)
    output: os.path.join(SCRATCH_DIR,"all_unmapped.fastq")
    message: "combining all unmapped reads to single fastq file"
    shell: "cat {input} > {output}"

########################################################################
rule read_distribution_count:
    input: raw=os.path.join(FQ_DIR,"{sample}.fastq"),
           trimmed=os.path.join(SCRATCH_DIR,"{sample}_trimmed.fastq"),
           nspike=os.path.join(SCRATCH_DIR,"{sample}_spike_unmapped.fastq"),
           ntransc=os.path.join(SCRATCH_DIR,"{sample}_tmap_transc_unmapped.fastq"),
           ngenome=os.path.join(SCRATCH_DIR,"{sample}_tmap_genome_unmapped.fastq"),
           ncontig=os.path.join(SCRATCH_DIR,"{sample}_tmap_contigs_unmapped.fastq")
    output: os.path.join(SCRATCH_DIR,"{sample}_readcnt.txt")
    message: "Count number of reads per class for sample {wildcards.sample}."
    shell:
        """
          rc_raw=$(($(cat     {input.raw}     | wc -l)/4))
          rc_trimmed=$(($(cat {input.trimmed} | wc -l)/4))
          rc_nspike=$(($(cat  {input.nspike}  | wc -l)/4))
          rc_ntransc=$(($(cat  {input.ntransc} | wc -l)/4))
          rc_ngenome=$(($(cat  {input.ngenome} | wc -l)/4))
          rc_ncontigs=$(($(cat {input.ncontig} | wc -l)/4))
          echo "sample\ttotal\ttrimmed\tspike\ttranscriptome\tgenome\tcontigs\tunmapped" > {output}
          echo -n "{wildcards.sample}\t"           >> {output}
          echo -n "$rc_raw\t"                      >> {output}
          echo -n "$((rc_raw-rc_trimmed))\t"       >> {output}
          echo -n "$((rc_trimmed-rc_nspike))\t"    >> {output}
          echo -n "$((rc_nspike-rc_ntransc))\t"    >> {output}
          echo -n "$((rc_ntransc-rc_ngenome))\t"   >> {output}
          echo -n "$((rc_ngenome-rc_ncontigs))\t"  >> {output}
          echo    "$rc_ncontigs"                   >> {output}
        """

########################################################################
rule genome_count_table:
    input: os.path.join(SCRATCH_DIR,"{sample}_tmap_genome.sam")
    output: os.path.join(RESULT_DIR,"{sample}_genome_cnt.txt")
    message: "Create count table"
    shell:
        """
          awk -v "b=100000" 'substr($1,1,1) == "@" {{ next; }} $2 == 0 {{ print $3 " - " b*int($4/b) }} $2 == 16 {{ print $3 " + " b*int($4/b)  }} ' {input} | sort  -k1,2 -k3n | uniq -c > {output}
        """

########################################################################
rule transcript_count_table:
    input: os.path.join(SCRATCH_DIR,"{sample}_tmap_transc.sam")
    output: os.path.join(RESULT_DIR,"{sample}_transc_cnt.txt")
    message: "Create count table"
    shell:
        """
          awk '$2 == 0 {{ print $3 }} $2 == 16 {{print $3 "_rc"}}'  {input} | sort | uniq -c > {output}
        """

########################################################################
rule tmap_index:
    input:  "{s}"
    output: "{s}.tmap.anno",
            "{s}.tmap.bwt",
            "{s}.tmap.pac",
            "{s}.tmap.sa"
    message: "Build an index for tmap"
    shell: "tmap index -f {input} "

########################################################################
rule euk_tmap_genome:
    input:  fq=os.path.join(SCRATCH_DIR,"{sample}_transc_unmapped.fastq"),
            db=GENOME_DB+".tmap.bwt"
    output: os.path.join(SCRATCH_DIR,"{sample}_tmap_genome.sam")
    message: "tmapping rest to genome"
    shell:
        """
          tmap mapall -r {input.fq} -f {GENOME_DB} {TMAP_PARAMS} > {output}
        """

########################################################################
rule tmap_transcriptome:
    input:  fq=os.path.join(SCRATCH_DIR,"{sample}_spike_unmapped.fastq"),
            db=TRANSCRIPTOME_DB+".tmap.bwt"
    output: os.path.join(SCRATCH_DIR,"{sample}_tmap_transc.sam")
    message: "tmapping to transcriptome"
    shell:  "tmap mapall -r {input.fq} -f {TRANSCRIPTOME_DB} {TMAP_PARAMS} > {output}"

########################################################################
rule extract_unmapped:
    input:  os.path.join(SCRATCH_DIR,"{s}.sam")
    output: os.path.join(SCRATCH_DIR,"{s}_unmapped.fastq")
    message: "Extract unmapped reads from sam to fastq"
    shell:
        """
          awk '$3=="*" {{printf("@%s\\n%s\\n+%s\\n%s\\n",$1,$10,$1,$11)}}' {input} > {output}
        """

########################################################################
# make spike count plots
rule spike_count_plots:
    input: totalcount=os.path.join(RESULT_DIR, "total_reads.csv"),
           spikecount=os.path.join(RESULT_DIR,"CountTable_spike.txt")
    output: countpng=os.path.join(RESULT_DIR,"count.png"),
            normcountpng=os.path.join(RESULT_DIR,"norm_count.png")
    run: R("""
             library(faradr);
             png(filename="{output.countpng}",width=1024,height=1024);
             plot(PlotSpikeCounts("{input.spikecount}"));
             dev.off();
             png(filename="{output.normcountpng}",width=1024,height=1024);
             plot(PlotNormalSpikeCounts("{input.spikecount}", "{input.totalcount}"));
             dev.off();
           """)

########################################################################
# Count the number of reads in the input fastq files. The
# method assumes single sequence and quality lines.
# By checking if the first character of every 4th line is
# a @ the assumption is tested.
# The much slower count_fq_reads function in sRNA_tools.py can
# be used if the assumption does not hold.
rule total_reads_count:
    input:  (FQ_DIR+"/{s}.fastq".format(s=sample) for sample in SAMPLES)
    output: os.path.join(RESULT_DIR, "total_reads.csv")
    message: "Count number of reads in the raw samples."
    shell:
        """
          echo -n "" > {output}
          for i in {FQ_DIR}/*.fastq ; do
             SAMPLE=$(basename $i .fastq)
             CNT=$(awk '(NR%4-1) {{next}} $1 ~ /^@/ {{sc++; next}} {{print "ERR"; exit -1}} END {{print sc}}' $i)
             echo "$SAMPLE\t$CNT" >> {output}
          done
        """

########################################################################
rule sam2bam:
    input:  "{sample}.sam"
    output: bam = "{sample}_sorted.bam",
            bai = "{sample}_sorted.bam.bai",
    message: "Converting {wildcards.sample} to sorted and indexed bam"
    shell:
        """
          samtools view -bS {input} > {output.bam}
          samtools sort {output.bam} {wildcards.sample}_sorted
          samtools index {output.bam}
        """

########################################################################
rule spike_count:
    input: ("{sd}/{sample}_spike_sorted.bam.bai".format(sample=s,sd=SCRATCH_DIR) for s in SAMPLES)
    output: os.path.join(RESULT_DIR,"CountTable_spike.txt"),
    message: "Counting spike reads"
    shell: "python sRNA_tools.py count_spikes --basename _spike_sorted.bam --spike_type ERCC --bam-dir {SCRATCH_DIR} --count-dir {RESULT_DIR}"

########################################################################
rule aln_spikes:
    input: os.path.join(SCRATCH_DIR,"{sample}_trimmed.fastq")
    output: os.path.join(SCRATCH_DIR,"{sample}_spike.sam")
    message: "Aligning reads to spike sequences."
    shell:
        """
          tmap mapall -r {input} -f {SPIKES_REF} {TMAP_PARAMS} > {output}
        """

########################################################################
rule trim_reads:
    input: os.path.join(FQ_DIR,"{sample}.fastq")
    output: os.path.join(SCRATCH_DIR,"{sample}_trimmed.fastq")
    message: "Trimming reads to {READ_TRIM_LEN} nt. And remove reads < 25nt"
    shell:
       """
         awk 'BEGIN {{tlen={READ_TRIM_LEN}; lmin=25}} {{ln++; av[ln] =$0}} ln==4 {{if (length($0)>=lmin) {{ printf("%s\\n%s\\n%s\\n%s\\n", av[1],substr(av[2],1,tlen),av[3],substr($0,1,tlen)); }} ln=0; }}'  {input} > {output}
       """

########################################################################
rule copy_to_result:
    input:  os.path.join(SCRATCH_DIR,"{s}")
    output: os.path.join(RESULT_DIR,"{s}")
    shell: "cp {input} {output}"

########################################################################
rule create_dir:
    output:  os.path.join("{s}",DIR_E)
    message: "Create directory {wildcards.s}"
    shell:   "mkdir -p {wildcards.s}; touch {output} "
